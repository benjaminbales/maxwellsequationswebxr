<!doctype html>
<!--
Copyright 2018 The Immersive Web Community Group

Permission is hereby granted, free of charge, to any person obtaining a copy of
this software and associated documentation files (the "Software"), to deal in
the Software without restriction, including without limitation the rights to
use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
the Software, and to permit persons to whom the Software is furnished to do so,
subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
-->
<html>
  <head>
    <meta charset='utf-8'>
    <meta name='viewport' content='width=device-width, initial-scale=1, user-scalable=no'>
    <meta name='mobile-web-app-capable' content='yes'>
    <meta name='apple-mobile-web-app-capable' content='yes'>
    <link rel='icon' type='image/png' sizes='32x32' href='favicon-32x32.png'>
    <link rel='icon' type='image/png' sizes='96x96' href='favicon-96x96.png'>
    <link rel='stylesheet' href='css/common.css'>

    <title>Maxwell's Equations WebXR App</title>
  </head>
  <body>
    <header>
      <details open>
        <summary>Maxwell's Equations</summary>
        <p>
          Learn the principles of electromagnetism
          in an immersive augmented reality 
          learning environment!
          <a class="back" href="./">Back</a>
        </p>
      </details>
    </header>
    <script type="module">
      import {WebXRButton} from './js/util/webxr-button.js';
      import {Scene} from './js/render/scenes/scene.js';
      import {Renderer, createWebGLContext} from './js/render/core/renderer.js';
      import {SkyboxNode} from './js/render/nodes/skybox.js';
      import {InlineViewerHelper} from './js/util/inline-viewer-helper.js';
      import {Gltf2Node} from './js/render/nodes/gltf2.js';
      import {QueryArgs} from './js/util/query-args.js';
      import {BoxBuilder} from './js/render/geometry/box-builder.js';
      import {PbrMaterial} from './js/render/materials/pbr.js';
      import {vec3, mat4, quat} from './js/render/math/gl-matrix.js';
      import {Ray} from './js/render/math/ray.js';
      import {Node} from './js/render/core/node.js';
      import {DropShadowNode} from './js/render/nodes/drop-shadow.js';

      // If requested, use the polyfill to provide support for mobile devices
      // and devices which only support WebVR.
      import WebXRPolyfill from './js/third-party/webxr-polyfill/build/webxr-polyfill.module.js';
      if (QueryArgs.getBool('usePolyfill', true)) {
        let polyfill = new WebXRPolyfill();
      }

      // XR globals.
      let xrButton = null;
      let xrImmersiveRefSpace = null;
      let inlineViewerHelper = null;

      // WebGL scene globals.
      let gl = null;
      let renderer = null;
      let scene = new Scene();

      let sphericalshell = new Node();
      sphericalshell.visible = false;
      sphericalshell.selectable = true;
      sphericalshell.addNode(new Gltf2Node({url: 'media/gltf/sphericalshell/sphericalshell.glb'}));
      scene.addNode(sphericalshell);

      // Having a really simple drop shadow underneath an object helps ground
      // it in the world without adding much complexity.
      // let shadow = new DropShadowNode();
      // vec3.set(shadow.scale, 0.15, 0.15, 0.15);
      // sphericalshell.addNode(shadow);

      let currentlySelectedObjects = [null, null];
      let currentlyGrabbedObjects = [null, null];
      let sphericalshells = [];
      let selecting = false;
      let grabDistance = .1; // 10cm
      let grabOrientation = quat.create(); // 10cm

      // Still adding a skybox, but only for the benefit of the inline view.
      let skybox = new SkyboxNode({url: 'media/textures/milky-way-4k.png'});
      scene.addNode(skybox);

      function initXR() {
        xrButton = new WebXRButton({
          onRequestSession: onRequestSession,
          onEndSession: onEndSession,
          textEnterXRTitle: "START AR",
          textXRNotFoundTitle: "AR NOT FOUND",
          textExitXRTitle: "EXIT  AR",
        });
        document.querySelector('header').appendChild(xrButton.domElement);

        if (navigator.xr) {
          // Checks to ensure that 'immersive-ar' mode is available, and only
          // enables the button if so.
          navigator.xr.isSessionSupported('immersive-ar').then((supported) => {
            xrButton.enabled = supported;
          });

          navigator.xr.requestSession('inline').then(onSessionStarted);
        }
      }

      function onRequestSession() {
        // Requests an 'immersive-ar' session, which ensures that the users
        // environment will be visible either via video passthrough or a
        // transparent display. This may be presented either in a headset or
        // fullscreen on a mobile device.
        return navigator.xr.requestSession('immersive-ar')
            .then((session) => {
              xrButton.setSession(session);
              session.isImmersive = true;
              onSessionStarted(session);
            });
      }

      function initGL() {
        if (gl)
          return;

        gl = createWebGLContext({
          xrCompatible: true
        });
        document.body.appendChild(gl.canvas);

        function onResize() {
          gl.canvas.width = gl.canvas.clientWidth * window.devicePixelRatio;
          gl.canvas.height = gl.canvas.clientHeight * window.devicePixelRatio;
        }
        window.addEventListener('resize', onResize);
        onResize();

        renderer = new Renderer(gl);

        scene.setRenderer(renderer);

        // Adds a new object to the scene at the
        // specificed transform.
        function addARObjectAt(translation) {
          let newSphericalShell = sphericalshell.clone();
          newSphericalShell.visible = true;
          newSphericalShell.selectable = true;
          newSphericalShell.translation = translation;
          scene.addNode(newSphericalShell);
          sphericalshells.push(newSphericalShell);
        }

        // Create several objects to use for hit testing.
        addARObjectAt(vec3.fromValues(-1.0, 0.0, -1.3));
        addARObjectAt(vec3.fromValues(0.0, 0.0, -1.5));
        addARObjectAt(vec3.fromValues(1.0, 0.0, -1.3));
      }

      function onSessionStarted(session) {
        session.addEventListener('end', onSessionEnded);

        // session.addEventListener('selectstart', onSelectStart);
        // session.addEventListener('selectend', onSelectEnd);
        // // By listening for the 'select' event we can find out when the user has
        // // performed some sort of primary input action and respond to it.
        // session.addEventListener('select', onSelect);

        session.addEventListener('selectstart', onSqueezeStart);
        session.addEventListener('selectend', onSqueezeEnd);
        // By listening for the 'select' event we can find out when the user has
        // performed some sort of primary input action and respond to it.
        session.addEventListener('select', onSqueeze);

        if (session.isImmersive) {
          // When in 'immersive-ar' mode don't draw an opaque background because
          // we want the real world to show through.
          skybox.visible = false;
        }

        initGL();

        // This and all future samples that visualize controllers will use this
        // convenience method to listen for changes to the active XRInputSources
        // and load the right meshes based on the profiles array.
        scene.inputRenderer.useProfileControllerMeshes(session);

        session.updateRenderState({ baseLayer: new XRWebGLLayer(session, gl) });

        let refSpaceType = session.isImmersive ? 'local' : 'viewer';
        session.requestReferenceSpace(refSpaceType).then((refSpace) => {
          if (session.isImmersive) {
            xrImmersiveRefSpace = refSpace;
          } else {
            inlineViewerHelper = new InlineViewerHelper(gl.canvas, refSpace);
          }
          session.requestAnimationFrame(onXRFrame);
        });
      }

      function onSelectStart(ev) {
        selecting = true; 
        console.log("selectstart " + currentlySelectedObjects);
        let refSpace = ev.frame.session.isImmersive ?
                         xrImmersiveRefSpace :
                         inlineViewerHelper.referenceSpace;
        let targetRayPose = ev.frame.getPose(ev.inputSource.targetRaySpace, refSpace);
        if (!targetRayPose) {
          return;
        }

        let hitResult = scene.hitTest(targetRayPose.transform);
        console.log( "targetRayPose.transform" + targetRayPose.transform); //benb
        if (hitResult) {
          // Check to see if the hit result was one of our objects.
          for (let sp of sphericalshells) {
            if (hitResult.node == sp) {
              let i = (ev.inputSource.handedness == "left") ? 0 : 1;
              currentlySelectedObjects[i] = sp;
              sp.scale = [1.25, 1.25, 1.25];
              sp.selected = false;
            }
          }
        }
      }

      function onSelect(ev) {
        let i = (ev.inputSource.handedness == "left") ? 0 : 1;
        let currentlySelectedObject = currentlySelectedObjects[i];  
        console.log("select " + currentlySelectedObject);
        if (currentlySelectedObject != null) {
          // Change the box color to something random.
          let uniforms = currentlySelectedObject.renderPrimitive.uniforms;
          uniforms.baseColorFactor.value = [Math.random(), Math.random(), Math.random(), 1.0];
          // it is expected that the scale is 1.25 (see onSelectStart). This should make the scale 0.75
          vec3.add(currentlySelectedObject.scale, currentlySelectedObject.scale, [-0.5, -0.5, -0.5]);
          currentlySelectedObject.selected = true;
        }
      }

      function onSelectEnd(ev) {
        selecting = false; 
        let i = (ev.inputSource.handedness == "left") ? 0 : 1;
        let currentlySelectedObject = currentlySelectedObjects[i];  
        console.log("selectend " + currentlySelectedObject);
        if (currentlySelectedObject != null) {
          if (currentlySelectedObject.selected) {
            // it is expected that the scale is 0.75 (see onSelectStart). This should make the scale 1.0
            vec3.add(currentlySelectedObject.scale, currentlySelectedObject.scale, [0.25, 0.25, 0.25]);
            currentlySelectedObject.selected = false;
          } else {
            // there was no 'select' event: final cube's size will be smaller.
            currentlySelectedObject.scale = [0.75, 0.75, 0.75];
          }
          currentlySelectedObjects[i] = null;
        }
      }

      function onSqueezeStart(ev) {
        console.log("squeezestart " + currentlyGrabbedObjects);
        let refSpace = ev.frame.session.isImmersive ?
                         xrImmersiveRefSpace :
                         inlineViewerHelper.referenceSpace;
        let targetRayPose = ev.frame.getPose(ev.inputSource.targetRaySpace, refSpace);
        if (!targetRayPose) {
          return;
        }

        let hitResult = scene.hitTest(targetRayPose.transform);
        if (hitResult) {
          // Check to see if the hit result was one of the scene objects.
          for (let sp of sphericalshells) {
            if (hitResult.node == sp && !sp.grabbed) {
              let i = (ev.inputSource.handedness == "left") ? 0 : 1;
              currentlyGrabbedObjects[i] = sp;
              // sp.scale = [0.1, 0.1, 0.1];
              sp.originalTrans = sp.translation;
              sp.grabbed = true;
              grabDistance = vec3.length(sp.translation);
              grabOrientation = sp.rotation;
            }
          }
        }
      }

      function onSqueeze(ev) {
        let i = (ev.inputSource.handedness == "left") ? 0 : 1;
        let currentlyGrabbedObject = currentlyGrabbedObjects[i];  
        console.log("squeeze " + currentlyGrabbedObject);
        if (currentlyGrabbedObject != null && currentlyGrabbedObject.grabbed) {
          // Change the box color to something random, so we can see that 'squeeze' was invoked.
          // let uniforms = currentlyGrabbedObject.renderPrimitive.uniforms;
          // uniforms.baseColorFactor.value = [Math.random(), Math.random(), Math.random(), 1.0];
        }
      }

      function onSqueezeEnd(ev) {
        let i = (ev.inputSource.handedness == "left") ? 0 : 1;
        let currentlyGrabbedObject = currentlyGrabbedObjects[i];  
        console.log("squeezeend " + currentlyGrabbedObject);
        if (currentlyGrabbedObject != null && currentlyGrabbedObject.grabbed) {
          // the scale of 'grabbed' box is 0.1. Restore the original scale.
          // vec3.add(currentlyGrabbedObject.scale, currentlyGrabbedObject.scale, [1, 1, 1]);
          // currentlyGrabbedObject.position = currentlyGrabbedObject.originalPos;
          currentlyGrabbedObject.grabbed = false;
          currentlyGrabbedObjects[i] = null;
        }
      }

      function onEndSession(session) {
        session.end();
      }

      function onSessionEnded(event) {
        if (event.session.isImmersive) {
          xrButton.setSession(null);
          // Turn the background back on when we go back to the inlive view.
          skybox.visible = true;
        }
      }

      // Called every time a XRSession requests that a new frame be drawn.
      function onXRFrame(time, frame) {
        let session = frame.session;
        let refSpace = session.isImmersive ?
                         xrImmersiveRefSpace :
                         inlineViewerHelper.referenceSpace;
        let pose = frame.getViewerPose(refSpace);

        scene.startFrame();

        session.requestAnimationFrame(onXRFrame);

        // check if we can move grabbed objects
        for (let inputSource of frame.session.inputSources) {
          //XRFrame.getPose returns the relative position and orientation—the pose—of one XRSpace to that of another space. 
          let targetRayPose = frame.getPose(inputSource.targetRaySpace, refSpace);

          if (!targetRayPose) {
            continue;
          }
          let i = (inputSource.handedness == "left") ? 0 : 1;
          if (currentlyGrabbedObjects[i] != null && currentlyGrabbedObjects[i].grabbed) {

            let targetRay = new Ray(targetRayPose.transform.matrix);

            let grabPos = vec3.fromValues(
                targetRay.origin[0], //x
                targetRay.origin[1], //y
                targetRay.origin[2]  //z
                );

            console.log("targetRay.origin[0] " + targetRay.origin[0]);
            console.log("targetRay.origin[1] " + targetRay.origin[1]);
            console.log("targetRay.origin[2] " + targetRay.origin[2]);

            // console.log("grabDistance " + grabDistance);

            vec3.add(grabPos, grabPos, [
                targetRay.direction[0] * grabDistance,
                targetRay.direction[1] * grabDistance, //+ 0.06, // 6 cm up to avoid collision with a ray
                targetRay.direction[2] * grabDistance,
                ]); 

            currentlyGrabbedObjects[i].translation = grabPos;
            
            let x = targetRayPose.transform.orientation.x;
            let y = targetRayPose.transform.orientation.y;
            let z = targetRayPose.transform.orientation.z;
            let w = targetRayPose.transform.orientation.w;

            currentlyGrabbedObjects[i].rotation = quat.fromValues(x, y, z, w);

            console.log("currentlyGrabbedObjects[i].rotation " + currentlyGrabbedObjects[i].rotation);
            console.log("targetRayPose.transform.orientation.x " + targetRayPose.transform.orientation.x);
            console.log("targetRayPose.transform.orientation.y " + targetRayPose.transform.orientation.y);
            console.log("targetRayPose.transform.orientation.z " + targetRayPose.transform.orientation.z);
            console.log("targetRayPose.transform.orientation.w " + targetRayPose.transform.orientation.w);
            // console.log("targetRayPose.transform.orientation.toJSON() " + targetRayPose.transform.orientation.toJSON());

              // currentlyGrabbedObjects[i].translation = vec3.fromValues(0, 0, -SPHERE_DISTANCE);
              // transformMat4(currentlyGrabbedObjects[i].translation, currentlyGrabbedObjects[i].translation, targetRayPose.transform.matrix);
              // currentlyGrabbedObjects[i].rotation = targetRayPose.transform.rotation;
          }
        }

        // for (let sp of sphericalshells) {
        //   let node = sp;
        //   mat4.identity(node.matrix);
        //   mat4.translate(node.matrix, node.matrix, sp.translation);
        //   mat4.rotateX(node.matrix, node.matrix, time/1000);
        //   mat4.rotateY(node.matrix, node.matrix, time/1500);
        //   mat4.scale(node.matrix, node.matrix, sp.scale);
        // }

        // In this sample and most samples after it we'll use a helper function
        // to automatically add the right meshes for the session's input sources
        // each frame. This also does simple hit detection to position the
        // cursors correctly on the surface of selectable nodes.
        scene.updateInputSources(frame, refSpace);

        scene.drawXRFrame(frame, pose);

        scene.endFrame();
      }

      // Start the XR application.
      initXR();
    </script>
  </body>
</html>
