<!doctype html>
<!--
Copyright 2018 The Immersive Web Community Group

Permission is hereby granted, free of charge, to any person obtaining a copy of
this software and associated documentation files (the "Software"), to deal in
the Software without restriction, including without limitation the rights to
use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
the Software, and to permit persons to whom the Software is furnished to do so,
subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
-->
<html>
  <head>
    <meta charset='utf-8'>
    <meta name='viewport' content='width=device-width, initial-scale=1, user-scalable=no'>
    <meta name='mobile-web-app-capable' content='yes'>
    <meta name='apple-mobile-web-app-capable' content='yes'>
    <link rel='icon' type='image/png' sizes='32x32' href='favicon-32x32.png'>
    <link rel='icon' type='image/png' sizes='96x96' href='favicon-96x96.png'>
    <link rel='stylesheet' href='css/common.css'>

    <title>Maxwell's Equations WebXR App</title>
  </head>
  <body>
    <header>
      <details open>
        <summary>Maxwell's Equations</summary>
        <p>
          Learn the principles of electromagnetism
          in an immersive augmented reality 
          learning environment!
          <a class="back" href="./">Back</a>
        </p>
      </details>
    </header>
    <script type="module">
      import {WebXRButton} from './js/util/webxr-button.js';
      import {Scene} from './js/render/scenes/scene.js';
      import {Renderer, createWebGLContext} from './js/render/core/renderer.js';
      import {SkyboxNode} from './js/render/nodes/skybox.js';
      import {InlineViewerHelper} from './js/util/inline-viewer-helper.js';
      import {Gltf2Node} from './js/render/nodes/gltf2.js';
      import {QueryArgs} from './js/util/query-args.js';
      import {BoxBuilder} from './js/render/geometry/box-builder.js';
      import {PbrMaterial} from './js/render/materials/pbr.js';
      import {vec3, mat4, quat} from './js/render/math/gl-matrix.js';
      import {Ray} from './js/render/math/ray.js';
      import {Node} from './js/render/core/node.js';
      import {DropShadowNode} from './js/render/nodes/drop-shadow.js';

      // If requested, use the polyfill to provide support for mobile devices
      // and devices which only support WebVR.
      import WebXRPolyfill from './js/third-party/webxr-polyfill/build/webxr-polyfill.module.js';
      if (QueryArgs.getBool('usePolyfill', true)) {
        let polyfill = new WebXRPolyfill();
      }

      // XR globals.
      let xrButton = null;
      let xrRefSpace = null;
      let xrViewerSpace = null;
      let xrHitTestSource = null;

      // WebGL scene globals.
      let gl = null;
      let renderer = null;
      let scene = new Scene();
      scene.enableStats(false);

      let sphericalshell = new Node();
      sphericalshell.visible = false;
      sphericalshell.selectable = true;
      sphericalshell.addNode(new Gltf2Node({url: 'media/gltf/sphericalshell/sphericalshell.glb'}));
      scene.addNode(sphericalshell);

      let reticle = new Gltf2Node({url: 'media/gltf/sphericalshell/sphericalshell.glb'});
      reticle.visible = false;
      scene.addNode(reticle);

      // Having a really simple drop shadow underneath an object helps ground
      // it in the world without adding much complexity.
      let shadow = new DropShadowNode();
      vec3.set(shadow.scale, 0.15, 0.15, 0.15);
      sphericalshell.addNode(shadow);

      let currentlySelectedObjects = [null, null];
      let currentlyGrabbedObjects = [null, null];
      let sphericalshells = [];
      const MAX_OBJECTS = 5;
      let grabDistance = .1; // 10cm
      let grabOrientation = quat.create();

      function initXR() {
        xrButton = new WebXRButton({
          onRequestSession: onRequestSession,
          onEndSession: onEndSession,
          textEnterXRTitle: "START AR",
          textXRNotFoundTitle: "AR NOT FOUND",
          textExitXRTitle: "EXIT  AR",
        });
        document.querySelector('header').appendChild(xrButton.domElement);

        if (navigator.xr) {
          // Checks to ensure that 'immersive-ar' mode is available, and only
          // enables the button if so.
          navigator.xr.isSessionSupported('immersive-ar').then((supported) => {
            xrButton.enabled = supported;
          });
        }
      }

      function onRequestSession() {
        // Requests an 'immersive-ar' session, which ensures that the users
        // environment will be visible either via video passthrough or a
        // transparent display. This may be presented either in a headset or
        // fullscreen on a mobile device.
        return navigator.xr.requestSession('immersive-ar', {requiredFeatures: ['local', 'hit-test']})
            .then((session) => {
              xrButton.setSession(session);
              onSessionStarted(session);
            });
      }

      function initGL() {
        if (gl)
          return;

        gl = createWebGLContext({
          xrCompatible: true
        });
        document.body.appendChild(gl.canvas);

        function onResize() {
          gl.canvas.width = gl.canvas.clientWidth * window.devicePixelRatio;
          gl.canvas.height = gl.canvas.clientHeight * window.devicePixelRatio;
        }
        window.addEventListener('resize', onResize);
        onResize();

        renderer = new Renderer(gl);

        scene.setRenderer(renderer);
      }

      // Adds a new object to the scene at the
      // specificed transform.
      function addARObjectAt(matrix) {
        let newSphericalShell = sphericalshell.clone();
        newSphericalShell.visible = true;
        newSphericalShell.selectable = true;
        // newSphericalShell.translation = translation;
        newSphericalShell.matrix = matrix;
        scene.addNode(newSphericalShell);
        sphericalshells.push(newSphericalShell);

        if (sphericalshells.length > MAX_OBJECTS) {
          let oldSphericalShell = sphericalshells.shift();
          scene.removeNode(oldSphericalShell);
          reticle.visible = false;
        }
      }

      function onSessionStarted(session) {

        session.addEventListener('end', onSessionEnded);

        session.addEventListener('selectstart', onSelectStart);

        session.addEventListener('select', onSelect);

        session.addEventListener('selectend', onSelectEnd);

        initGL();

        // This and all future samples that visualize controllers will use this
        // convenience method to listen for changes to the active XRInputSources
        // and load the right meshes based on the profiles array.
        scene.inputRenderer.useProfileControllerMeshes(session);

        session.updateRenderState({ baseLayer: new XRWebGLLayer(session, gl) });

        // Cast a ray straight out from the viewer's position and render a reticle 
        // where it intersects with a real world surface. To do this we first 
        // get the viewer space, then create a hitTestSource that tracks it.
        session.requestReferenceSpace('viewer').then((refSpace) => {
          xrViewerSpace = refSpace;
          session.requestHitTestSource({ space: xrViewerSpace }).then((hitTestSource) => {
            xrHitTestSource = hitTestSource;
          });
        });

        session.requestReferenceSpace('local').then((refSpace) => {
          xrRefSpace = refSpace;

          session.requestAnimationFrame(onXRFrame);
        });
      }

      function onEndSession(session) {
        xrHitTestSource.cancel();
        xrHitTestSource = null;
        session.end();
      }

      function onSessionEnded(event) {
          xrButton.setSession(null);
      }

      function onSelectStart(ev) {
        if(!reticle.visible){
          console.log("Selectstart " + currentlyGrabbedObjects);
          let targetRayPose = ev.frame.getPose(ev.inputSource.targetRaySpace, xrRefSpace);
          if (!targetRayPose) {
            return;
          }

          let hitResult = scene.hitTest(targetRayPose.transform);
          if (hitResult) {
            // Check to see if the hit result was one of the scene objects.
            for (let sp of sphericalshells) {
              if (hitResult.node == sp && !sp.grabbed) {
                let i = (ev.inputSource.handedness == "left") ? 0 : 1;
                currentlyGrabbedObjects[i] = sp;
                sp.scale = [0.1, 0.1, 0.1];
                // sp.originalTrans = sp.translation;
                sp.grabbed = true;
                grabDistance = vec3.length(sp.translation);
                // grabOrientation = sp.rotation;
              }
            }
          }
        }
      }

      function onSelect(ev) {
        // The reticle should already be positioned at the latest hit point, 
        // so we can just use it's matrix to save an unnecessary call to 
        // event.frame.getHitTestResults.
        if (reticle.visible) {
          addARObjectAt(reticle.matrix);
        }
      }

      function onSelectEnd(ev) {
        if(!reticle.visible){
          let i = (ev.inputSource.handedness == "left") ? 0 : 1;
          let currentlyGrabbedObject = currentlyGrabbedObjects[i];  
          console.log("Selectend " + currentlyGrabbedObject);
          if (currentlyGrabbedObject != null && currentlyGrabbedObject.grabbed) {
            currentlyGrabbedObject.grabbed = false;
            currentlyGrabbedObject.scale = [1, 1, 1];
            currentlyGrabbedObjects[i] = null;
          }
        }
      }

      function handleInputs(frame, refSpace){
        // check if we can move grabbed objects
        for (let inputSource of frame.session.inputSources) {
          //XRFrame.getPose returns the relative position and orientation—the pose—of one XRSpace to that of another space. 
          let targetRayPose = frame.getPose(inputSource.targetRaySpace, refSpace);

          if (!targetRayPose) {
            continue;
          }

          let i = (inputSource.handedness == "left") ? 0 : 1;
          if (currentlyGrabbedObjects[i] != null && currentlyGrabbedObjects[i].grabbed) {

            let targetRay = new Ray(targetRayPose.transform.matrix);

            let grabPos = vec3.fromValues(
                targetRay.origin[0], //x
                targetRay.origin[1], //y
                targetRay.origin[2]  //z
                );

            vec3.add(grabPos, grabPos, [
                targetRay.direction[0] * grabDistance,
                targetRay.direction[1] * grabDistance, //+ 0.06, // 6 cm up to avoid collision with a ray
                targetRay.direction[2] * grabDistance,
                ]); 

            currentlyGrabbedObjects[i].translation = grabPos;
            
            let x = targetRayPose.transform.orientation.x;
            let y = targetRayPose.transform.orientation.y;
            let z = targetRayPose.transform.orientation.z;
            let w = targetRayPose.transform.orientation.w;

            currentlyGrabbedObjects[i].rotation = quat.fromValues(x, y, z, w);
          }
        }
      }

      // Called every time a XRSession requests that a new frame be drawn.
      function onXRFrame(time, frame) {
        let session = frame.session;

        let pose = frame.getViewerPose(xrRefSpace);

        // If we have a hit test source, get its results for the frame
        // and use the pose to display a reticle in the scene.
        if (xrHitTestSource && pose) {
          let hitTestResults = frame.getHitTestResults(xrHitTestSource);

          if ((hitTestResults.length > 0) && (sphericalshells.length < MAX_OBJECTS)) {
            let pose = hitTestResults[0].getPose(xrRefSpace);
            reticle.visible = true;
            reticle.matrix = pose.transform.matrix;
          }else{
            reticle.visible = false;
          }
        }

        scene.startFrame();

        session.requestAnimationFrame(onXRFrame);

        handleInputs(frame, xrRefSpace);

        // In this sample and most samples after it we'll use a helper function
        // to automatically add the right meshes for the session's input sources
        // each frame. This also does simple hit detection to position the
        // cursors correctly on the surface of selectable nodes.
        scene.updateInputSources(frame, xrRefSpace);

        scene.drawXRFrame(frame, pose);

        scene.endFrame();
      }

      // Start the XR application.
      initXR();
    </script>
  </body>
</html>
